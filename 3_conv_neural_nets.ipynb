{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Neural Networks :  Cats vs Dogs  (with GPU support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 121/12501 [00:00<00:10, 1202.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PetImages/Cat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12501/12501 [00:10<00:00, 1204.60it/s]\n",
      "  1%|          | 105/12501 [00:00<00:11, 1046.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PetImages/Dog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12501/12501 [00:10<00:00, 1155.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat class =  12476\n",
      "Dog class =  12470\n"
     ]
    }
   ],
   "source": [
    "REBUILD_DATA = True\n",
    "class dvc():\n",
    "    IMG_SIZE = 50\n",
    "    PADDING = 5\n",
    "    CATS = \"PetImages/Cat\"\n",
    "    DOGS = \"PetImages/Dog\"\n",
    "    LABELS = {CATS :0 , DOGS :1}\n",
    "    training_data = []\n",
    "    catcount = 0\n",
    "    dogcount = 0\n",
    "    \n",
    "    def make_training_data(self):\n",
    "        for label in self.LABELS:\n",
    "            print(label)\n",
    "            for file in tqdm(os.listdir(label)):\n",
    "                try:   #SOME IMAGES MAYBE CORRUPT\n",
    "                    path = os.path.join(label,file)\n",
    "                    #convert image to grayscale to keep it simple\n",
    "                    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                    #resize to 50*50\n",
    "                    #print(img)\n",
    "                    img = cv2.resize(img, (self.IMG_SIZE,self.IMG_SIZE))\n",
    "                    img = cv2.copyMakeBorder(img,self.PADDING,self.PADDING,self.PADDING,self.PADDING,cv2.BORDER_CONSTANT,value=0)\n",
    "                    self.training_data.append([np.array(img),np.eye(2)[self.LABELS[label]]])\n",
    "                    #print(label,self.CATS)\n",
    "                    if str(label) == str(self.CATS):\n",
    "                        self.catcount += 1\n",
    "                    elif str(label) == str(self.DOGS):    \n",
    "                        self.dogcount += 1\n",
    "                except Exception as e:\n",
    "                    #print(e)\n",
    "                    pass\n",
    "        np.random.shuffle(self.training_data)\n",
    "        np.save(\"training_data_padded.npy\",self.training_data)\n",
    "        \n",
    "        print(\"Cat class = \",self.catcount)\n",
    "        print(\"Dog class = \",self.dogcount)\n",
    "        \n",
    "if REBUILD_DATA:\n",
    "    dc = dvc()\n",
    "    dc.make_training_data()\n",
    "    \n",
    "    \n",
    "         \n",
    "                \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24946"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dc.training_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       "       array([1., 0.])], dtype=object)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load(\"training_data_padded.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meow with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(training_data[5][0],cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "class cnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,32,5)      # 1 image, 32 channels, 5*5 krnel default stride=1\n",
    "        self.conv2 = nn.Conv2d(32,64,5)\n",
    "        self.conv3 = nn.Conv2d(64,128,5)\n",
    "        \n",
    "    \n",
    "        x = torch.randn(1,60,60).view(-1,1,60,60)\n",
    "        self.to_linear = None   #auxillary variable to calculate shape of output of conv+max_pool\n",
    "        self.convs(x)        \n",
    "        \n",
    "        self.fc1 = nn.Linear(self.to_linear,512)\n",
    "        self.fc2 = nn.Linear(512,256)\n",
    "        self.fc3 = nn.Linear(256,2)\n",
    "        \n",
    "    def convs(self,x):\n",
    "\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),(2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)),(2,2))\n",
    "        #x = self.model(x)\n",
    "        if self.to_linear is None:\n",
    "            self.to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        return x\n",
    "    def forward(self,x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1,self.to_linear)   #flattening\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.softmax(x,dim=1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Process\n"
     ]
    }
   ],
   "source": [
    "## Do check for cuda device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"GPU Process\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CPU Process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cnet().to(device)   #transferiing class objet to gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(net.parameters(),lr=0.001)\n",
    "loss_function = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPARING TRAINING,TESTING\n",
    "\n",
    "X = torch.Tensor([i[0] for i in training_data]).view(-1,60,60)\n",
    "X = X/255.0\n",
    "y = torch.Tensor([i[1] for i in training_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0.])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2494\n"
     ]
    }
   ],
   "source": [
    "val_ratio = 0.1\n",
    "val_size = int(len(X)*val_ratio)\n",
    "print(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = X[:-val_size]\n",
    "train_y = y[:-val_size]\n",
    "test_X = X[-val_size:]\n",
    "test_y = y[-val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22452 22452\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X),len(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net):    \n",
    "    BATCH_SIZE = 64\n",
    "    EPOCHS = 20\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i in tqdm(range(0,len(train_X),BATCH_SIZE)):\n",
    "            batch_X = train_X[i:i+BATCH_SIZE].view(-1,1,60,60)\n",
    "            batch_y = train_y[i:i+BATCH_SIZE]\n",
    "            batch_X,batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            net.zero_grad()\n",
    "            out = net(batch_X)\n",
    "            #print(out.size())\n",
    "            #print(batch_y.size())\n",
    "            loss = loss_function(out,batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Epoch = \"+str(epoch)+\", loss = \"+str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(len(test_X))):\n",
    "            real_class = torch.argmax(test_y[i]).to(device)\n",
    "            net_out = net(test_X[i].view(-1, 1, 60, 60).to(device))[0]  # returns a list, \n",
    "            #print(net_out)\n",
    "            #print(real_class)\n",
    "            predicted_class = torch.argmax(net_out)\n",
    "\n",
    "            if predicted_class == real_class:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:06<00:00, 54.81it/s]\n",
      "  2%|▏         | 6/351 [00:00<00:05, 59.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, loss = tensor(0.7096, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:06<00:00, 54.60it/s]\n",
      "  2%|▏         | 6/351 [00:00<00:05, 57.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, loss = tensor(0.6673, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:06<00:00, 54.91it/s]\n",
      "  2%|▏         | 6/351 [00:00<00:05, 58.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2, loss = tensor(0.5967, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:06<00:00, 54.78it/s]\n",
      "  2%|▏         | 6/351 [00:00<00:05, 58.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 3, loss = tensor(0.5034, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:06<00:00, 54.94it/s]\n",
      "  2%|▏         | 6/351 [00:00<00:05, 58.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4, loss = tensor(0.5035, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:06<00:00, 54.62it/s]\n",
      "  2%|▏         | 6/351 [00:00<00:05, 58.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5, loss = tensor(0.4278, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:06<00:00, 54.88it/s]\n",
      "  2%|▏         | 6/351 [00:00<00:05, 59.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 6, loss = tensor(0.4525, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:06<00:00, 54.75it/s]\n",
      "  2%|▏         | 6/351 [00:00<00:05, 58.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 7, loss = tensor(0.4822, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:06<00:00, 54.86it/s]\n",
      "  2%|▏         | 6/351 [00:00<00:05, 59.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 8, loss = tensor(0.8393, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:06<00:00, 54.66it/s]\n",
      "  2%|▏         | 6/351 [00:00<00:05, 58.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 9, loss = tensor(0.3667, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:06<00:00, 54.87it/s]\n",
      "  2%|▏         | 6/351 [00:00<00:05, 59.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 10, loss = tensor(0.3118, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:06<00:00, 54.79it/s]\n",
      "  2%|▏         | 6/351 [00:00<00:05, 59.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 11, loss = tensor(0.1657, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:06<00:00, 54.83it/s]\n",
      "  2%|▏         | 6/351 [00:00<00:05, 58.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 12, loss = tensor(0.2005, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:06<00:00, 54.29it/s]\n",
      "  2%|▏         | 6/351 [00:00<00:05, 59.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 13, loss = tensor(0.2316, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:06<00:00, 53.70it/s]\n",
      "  2%|▏         | 6/351 [00:00<00:05, 58.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 14, loss = tensor(0.0457, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:06<00:00, 54.78it/s]\n",
      "  2%|▏         | 6/351 [00:00<00:05, 59.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 15, loss = tensor(0.1417, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:06<00:00, 54.78it/s]\n",
      "  2%|▏         | 6/351 [00:00<00:05, 58.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 16, loss = tensor(0.0721, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:06<00:00, 54.84it/s]\n",
      "  2%|▏         | 6/351 [00:00<00:05, 59.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 17, loss = tensor(0.0111, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:06<00:00, 54.80it/s]\n",
      "  2%|▏         | 6/351 [00:00<00:05, 58.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 18, loss = tensor(0.0437, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:06<00:00, 54.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 19, loss = tensor(0.0072, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2494/2494 [00:01<00:00, 1609.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test(net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
